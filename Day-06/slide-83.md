1. **Irreversible High-Stakes Decisions**

   * Book kehta hai ke pehle careful testing aur evaluation zaroori hai. Aise kaam jahan galti ka nuksan bohot zyada ho, jaise medical diagnosis ya legal judgment, wahan AI ko akela nahi chhodna chahiye. Humans ka review zaroori hai, jaise “Golden Dataset” testing step mein 97%+ accuracy check hoti hai before release.

2. **Undefined Success Criteria**

   * AI tabhi acha kaam karta hai jab objectives clear hon. Agar success measure nahi kiya ja sakta to performance validate nahi ho sakti. Book kehta hai ke domain knowledge aur clear specification zaroori hai, jo tabhi possible hai jab success criteria defined ho.

3. **Unstable Data Environments**

   * Agar data frequently change hota hai, ya data quality poor hai, AI reliable nahi rahegi. Book recommend karti hai **shadow mode**, matlab AI suggestions de, humans execute karein, aur 95%+ accuracy achieve hone ke baad hi full automation start karein.

4. **Relationship-Critical Interactions**

   * Sensitive communications jaise HR issues ya crisis management mein AI galti risk zyada hota hai. Book kehti hai ke **strategic restraint** adopt karo—maximum automation pe mat jao, humans involvement se long-term value protect hoti hai.

✅ **Core Principle**: Strategic restraint—AI ko sirf wahan deploy karo jahan wo reliably efficiency improve kare. Agar stakes high hon, data unstable ho, ya success unclear ho, to pause karo, test karo, ya redesign karo.
